{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_xfx2e4xoo59"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "from math import sqrt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.layers import Bidirectional, Dropout\n",
        "from keras.regularizers import l2\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, Bidirectional, LSTM, Dropout, Dense, BatchNormalization\n",
        "from keras.regularizers import l2\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import EarlyStopping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WTPBt_Ht0bg-"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"author_profiling_v3.csv\")\n",
        "df['tweets_lemmatized'] = df['tweets_lemmatized'].astype(str)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EkUuOBJMze73"
      },
      "outputs": [],
      "source": [
        "# Initialize the tokenizer\n",
        "tokenizer = Tokenizer()\n",
        "\n",
        "# The target values are in the columns 'ext', 'neu', 'agr', 'con', 'ope'\n",
        "y = df[['ext', 'neu', 'agr', 'con', 'ope']].values\n",
        "\n",
        "# Split the data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['tweets_lemmatized'], y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Fit the tokenizer on the TRAINING tweets\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "\n",
        "# Transform the TRAINING tweets into sequences of integers\n",
        "sequences_train = tokenizer.texts_to_sequences(X_train)\n",
        "\n",
        "# Transform the TEST tweets into sequences of integers\n",
        "sequences_test = tokenizer.texts_to_sequences(X_test)\n",
        "\n",
        "# Pad the TRAINING sequences so they all have the same length\n",
        "X_train = pad_sequences(sequences_train, maxlen=max_sequence_length)\n",
        "\n",
        "# Pad the TEST sequences so they all have the same length\n",
        "X_test = pad_sequences(sequences_test, maxlen=max_sequence_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m-nbGH_c4_Ia",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82770632-7ac7-4c69-c576-1dcbbb861c52"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "704/704 [==============================] - 26s 28ms/step - loss: 0.2234 - val_loss: 0.0430\n",
            "Epoch 2/10\n",
            "704/704 [==============================] - 19s 27ms/step - loss: 0.0344 - val_loss: 0.6344\n",
            "Epoch 3/10\n",
            "704/704 [==============================] - 18s 26ms/step - loss: 0.0254 - val_loss: 0.0312\n",
            "Epoch 4/10\n",
            "704/704 [==============================] - 19s 27ms/step - loss: 0.0205 - val_loss: 0.0329\n",
            "Epoch 5/10\n",
            "704/704 [==============================] - 19s 27ms/step - loss: 0.0179 - val_loss: 0.0347\n",
            "Epoch 6/10\n",
            "704/704 [==============================] - 18s 26ms/step - loss: 0.0164 - val_loss: 0.0321\n",
            "220/220 [==============================] - 2s 10ms/step - loss: 0.0320\n"
          ]
        }
      ],
      "source": [
        "# Define early stopping\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
        "# Define the BiLSTM model\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=len(tokenizer.word_index)+1, output_dim=128, input_length=max_sequence_length))\n",
        "model.add(Bidirectional(LSTM(128, return_sequences=True)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Bidirectional(LSTM(128)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(5, kernel_regularizer=l2(0.03)))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='mean_squared_error', optimizer=Adam())\n",
        "\n",
        "# Define early stopping\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
        "\n",
        "# Add these callbacks to the fit() function\n",
        "model.fit(X_train, y_train, epochs=10, validation_split=0.2, callbacks=[early_stopping])\n",
        "\n",
        "# Evaluate the model\n",
        "loss = model.evaluate(X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xW5pStOV1lSs",
        "outputId": "43ddefbb-a8cd-41bc-9d7c-b7400afddb17"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "880/880 [==============================] - 9s 9ms/step\n",
            "ext:\n",
            "  MAE:  0.1011\n",
            "  MSE:  0.0180\n",
            "  RMSE: 0.1341\n",
            "  R^2:  0.3160\n",
            "neu:\n",
            "  MAE:  0.1153\n",
            "  MSE:  0.0251\n",
            "  RMSE: 0.1585\n",
            "  R^2:  0.5231\n",
            "agr:\n",
            "  MAE:  0.0862\n",
            "  MSE:  0.0138\n",
            "  RMSE: 0.1176\n",
            "  R^2:  0.4161\n",
            "con:\n",
            "  MAE:  0.0864\n",
            "  MSE:  0.0132\n",
            "  RMSE: 0.1150\n",
            "  R^2:  0.4185\n",
            "ope:\n",
            "  MAE:  0.0834\n",
            "  MSE:  0.0123\n",
            "  RMSE: 0.1108\n",
            "  R^2:  0.4823\n"
          ]
        }
      ],
      "source": [
        "# RMSE MAE MSE R^2 for training dataset to evaluate if the model is overfitting or underfitting\n",
        "predictions =model.predict(X_train)\n",
        "\n",
        "trait_names = ['ext', 'neu', 'agr', 'con', 'ope']\n",
        "\n",
        "# Loop over each trait\n",
        "for i in range(5):\n",
        "    # Select the true and predicted values for this trait\n",
        "    y_true = y_train[:, i]\n",
        "    y_pred = predictions[:, i]\n",
        "\n",
        "    # Compute metrics\n",
        "    mae = mean_absolute_error(y_true, y_pred)\n",
        "    mse = mean_squared_error(y_true, y_pred)\n",
        "    rmse = np.sqrt(mse)  # RMSE is just the square root of MSE\n",
        "    r2 = r2_score(y_true, y_pred)\n",
        "\n",
        "    # Print results\n",
        "    print(f\"{trait_names[i]}:\")\n",
        "    print(f\"  MAE:  {mae:.4f}\")\n",
        "    print(f\"  MSE:  {mse:.4f}\")\n",
        "    print(f\"  RMSE: {rmse:.4f}\")\n",
        "    print(f\"  R^2:  {r2:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ljsQZDON21Xh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70e90ef4-021b-48b8-a70b-8fe406d0f71a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "220/220 [==============================] - 2s 11ms/step\n",
            "ext:\n",
            "  MAE:  0.1357\n",
            "  MSE:  0.0308\n",
            "  RMSE: 0.1756\n",
            "  R^2:  -0.1700\n",
            "neu:\n",
            "  MAE:  0.1818\n",
            "  MSE:  0.0534\n",
            "  RMSE: 0.2311\n",
            "  R^2:  -0.0406\n",
            "agr:\n",
            "  MAE:  0.1226\n",
            "  MSE:  0.0260\n",
            "  RMSE: 0.1614\n",
            "  R^2:  -0.0821\n",
            "con:\n",
            "  MAE:  0.1189\n",
            "  MSE:  0.0224\n",
            "  RMSE: 0.1498\n",
            "  R^2:  -0.0023\n",
            "ope:\n",
            "  MAE:  0.1232\n",
            "  MSE:  0.0236\n",
            "  RMSE: 0.1537\n",
            "  R^2:  0.0047\n"
          ]
        }
      ],
      "source": [
        "# Make predictions\n",
        "predictions = model.predict(X_test)\n",
        "\n",
        "trait_names = ['ext', 'neu', 'agr', 'con', 'ope']\n",
        "\n",
        "# Loop over each trait\n",
        "for i in range(5):\n",
        "    # Select the true and predicted values for this trait\n",
        "    y_true = y_test[:, i]\n",
        "    y_pred = predictions[:, i]\n",
        "\n",
        "    # Compute metrics\n",
        "    mae = mean_absolute_error(y_true, y_pred)\n",
        "    mse = mean_squared_error(y_true, y_pred)\n",
        "    rmse = np.sqrt(mse)  # RMSE is just the square root of MSE\n",
        "    r2 = r2_score(y_true, y_pred)\n",
        "\n",
        "    # Print results\n",
        "    print(f\"{trait_names[i]}:\")\n",
        "    print(f\"  MAE:  {mae:.4f}\")\n",
        "    print(f\"  MSE:  {mse:.4f}\")\n",
        "    print(f\"  RMSE: {rmse:.4f}\")\n",
        "    print(f\"  R^2:  {r2:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FzfEGVTSqM2I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97755626-b65f-47e6-e37a-a9075ede25b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          ext       neu       agr       con       ope\n",
            "ext  1.000000  0.395092  0.234762  0.188441 -0.139757\n",
            "neu  0.395092  1.000000  0.309274 -0.179619 -0.141880\n",
            "agr  0.234762  0.309274  1.000000  0.100772 -0.078458\n",
            "con  0.188441 -0.179619  0.100772  1.000000  0.204890\n",
            "ope -0.139757 -0.141880 -0.078458  0.204890  1.000000\n"
          ]
        }
      ],
      "source": [
        "# Convert the predictions to a DataFrame\n",
        "predictions_df = pd.DataFrame(predictions, columns=trait_names)\n",
        "\n",
        "# Compute the correlation matrix\n",
        "correlation_matrix = predictions_df.corr()\n",
        "\n",
        "# Print the correlation matrix\n",
        "print(correlation_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PTiG-xXXzTLH",
        "outputId": "d50c6f09-2e0f-48a3-8041-390425735b49"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          ext       neu       agr       con       ope\n",
            "ext  1.000000  0.294476  0.145334  0.192219  0.020805\n",
            "neu  0.294476  1.000000  0.325530  0.021377 -0.029465\n",
            "agr  0.145334  0.325530  1.000000  0.070499 -0.004108\n",
            "con  0.192219  0.021377  0.070499  1.000000  0.071473\n",
            "ope  0.020805 -0.029465 -0.004108  0.071473  1.000000\n"
          ]
        }
      ],
      "source": [
        "correlation_matrix = df[['ext', 'neu', 'agr', 'con', 'ope']].corr()\n",
        "print(correlation_matrix)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}